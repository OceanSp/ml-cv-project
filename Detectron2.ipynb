{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Detectron2 Beginner's Tutorial\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
        "* Run inference on images or videos, with an existing detectron2 model\n",
        "* Train a detectron2 model on a new dataset\n",
        "\n",
        "You can make a copy of this tutorial by \"File -> Open in playground mode\" and make changes there. __DO NOT__ request access to this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FsePPpwZSmqt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[37 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-7ei6ycn8/pyyaml_9cb640e3af2e4c11acd83e972d74aec7/setup.py\", line 291, in <module>\n",
            "  \u001b[31m   \u001b[0m     setup(\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
            "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
            "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
            "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/dist.py\", line 963, in run_command\n",
            "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
            "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/egg_info.py\", line 321, in run\n",
            "  \u001b[31m   \u001b[0m     self.find_sources()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/egg_info.py\", line 329, in find_sources\n",
            "  \u001b[31m   \u001b[0m     mm.run()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/egg_info.py\", line 551, in run\n",
            "  \u001b[31m   \u001b[0m     self.add_defaults()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/egg_info.py\", line 589, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/command/sdist.py\", line 112, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     super().add_defaults()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/sdist.py\", line 251, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/command/sdist.py\", line 336, in _add_defaults_ext\n",
            "  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n",
            "  \u001b[31m   \u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-7ei6ycn8/pyyaml_9cb640e3af2e4c11acd83e972d74aec7/setup.py\", line 199, in get_source_files\n",
            "  \u001b[31m   \u001b[0m     self.cython_sources(ext.sources, ext)\n",
            "  \u001b[31m   \u001b[0m     ^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n",
            "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
            "  \u001b[31m   \u001b[0m AttributeError: cython_sources\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "\u001b[?25hfatal: destination path 'detectron2' already exists and is not an empty directory.\n",
            "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (9.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
            "Collecting pycocotools>=2.0.2\n",
            "  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.15.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black\n",
            "  Downloading black-24.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from yacs>=0.1.8) (5.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.26.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.23.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (69.0.3)\n",
            "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.0.1)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black) (4.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/lib/python3/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.0)\n",
            "Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.7/458.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61406 sha256=efd67e8cb999446c54e0fe12647f5346fc11cfaa5fe353be2751af2329f50509\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, pycocotools, fvcore\n",
            "Successfully installed black-24.10.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 pathspec-0.12.1 portalocker-3.1.1 pycocotools-2.0.8 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d288Z2mF5dC",
        "outputId": "c47c5426-64d6-4632-f868-e2f14dfe39be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Mon_Oct_24_19:12:58_PDT_2022\n",
            "Cuda compilation tools, release 12.0, V12.0.76\n",
            "Build cuda_12.0.r12.0/compiler.31968024_0\n",
            "torch:  2.1 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matplotlib data path: /usr/local/lib/python3.11/dist-packages/matplotlib/mpl-data\n",
            "CONFIGDIR=/root/.config/matplotlib\n",
            "interactive is False\n",
            "platform is linux\n",
            "CACHEDIR=/root/.cache/matplotlib\n",
            "font search path [PosixPath('/usr/local/lib/python3.11/dist-packages/matplotlib/mpl-data/fonts/ttf'), PosixPath('/usr/local/lib/python3.11/dist-packages/matplotlib/mpl-data/fonts/afm'), PosixPath('/usr/local/lib/python3.11/dist-packages/matplotlib/mpl-data/fonts/pdfcorefonts')]\n",
            "generated new fontManager\n"
          ]
        }
      ],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n",
        "which only has one class: balloon.\n",
        "We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that COCO dataset does not have the \"balloon\" category. We'll be able to recognize this new class in a few minutes.\n",
        "\n",
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kagglehub\n",
            "  Downloading kagglehub-0.3.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kagglehub) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->kagglehub) (2020.6.20)\n",
            "Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kagglehub\n",
            "Successfully installed kagglehub-0.3.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qg7zSVOulkb",
        "outputId": "b3c3e5b1-44f0-4402-bd63-076af70ef442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting new HTTPS connection (1): www.kaggle.com:443\n",
            "https://www.kaggle.com:443 \"GET /api/v1/datasets/view/jaidalmotra/weed-detection HTTP/1.1\" 200 None\n",
            "Starting new HTTPS connection (1): www.kaggle.com:443\n",
            "https://www.kaggle.com:443 \"GET /api/v1/datasets/download/jaidalmotra/weed-detection?dataset_version_number=1 HTTP/1.1\" 302 0\n",
            "Starting new HTTPS connection (1): storage.googleapis.com:443\n",
            "https://storage.googleapis.com:443 \"GET /kaggle-data-sets/3851613/6675836/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250111%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250111T010134Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4d2a5542d8e7e120b876fbabe451d6817313d9a646500193aa8869227a1626cbb4d9422329ff8b926e74d16138af1295338819afea86fd0ffe191af44b6592699a3dd5afd3987089f1fb728f47ec9c9d1f605d3a3ce6c2ed275a6aea4a51b2ba03ebf80506adf10da9159b8fb4d641a05ee7ba9bfeaad38a0c1e0d98d7c2d1acdfd2866ea9b1105de98f32ee66693af5a9c94d6d5b651970310bf772f280e4fd15e2f12fc4b7a438cc01e8f3ad4f10ce7282877ada2a01e3b213a45d23e992a27a0e44bf65aa45b2e992b3a3fe8b866c3f1e6ca1ce33fd807a563b6aceae1de5668a63fda1e544a301175bb92fe3b1a1521f86d1f1193f2ebf214272f95c8fff HTTP/1.1\" 200 163743041\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jaidalmotra/weed-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 156M/156M [00:01<00:00, 131MB/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jaidalmotra/weed-detection\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "# Define paths for train and test data\n",
        "train_folder = os.path.join(path, 'train')\n",
        "test_folder = os.path.join(path, 'test')\n",
        "annotations_train = os.path.join(train_folder, '_annotations.coco.json')\n",
        "annotations_test = os.path.join(test_folder, '_annotations.coco.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PIbAM2pv-urF"
      },
      "outputs": [],
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"weed_train\", {}, annotations_train, train_folder)\n",
        "register_coco_instances(\"weed_val\", {}, annotations_test, test_folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "## Train!\n",
        "\n",
        "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import detectron2\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
        "        return COCOEvaluator(\n",
        "            dataset_name=dataset_name,\n",
        "            tasks=[\"bbox\"],   # or None to infer automatically\n",
        "            distributed=True,\n",
        "            output_dir=output_folder,\n",
        "            max_dets_per_image=100,\n",
        "            use_fast_impl=True,      # optional, depends on your needs\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7unkuuiqLdqd",
        "outputId": "ba1716cd-3f3b-401d-bae5-8fbbd2199d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[01/11 01:21:41 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:21:41 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:21:41 d2.data.datasets.coco]: \u001b[0mLoaded 1661 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/train/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:21:41 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 1655 images left.\n",
            "\u001b[32m[01/11 01:21:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[01/11 01:21:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[01/11 01:21:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:21:41 d2.data.common]: \u001b[0mSerializing 1655 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:21:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n",
            "\u001b[32m[01/11 01:21:41 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n",
            "\u001b[32m[01/11 01:21:41 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n",
            "[Checkpointer] Loading from /root/.torch/iopath_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n",
            "Reading a file from 'Detectron2 Model Zoo'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[01/11 01:21:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:21:50 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:21:50 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:21:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:21:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:21:50 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:21:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:21:50 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:21:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0015 s/iter. Inference: 0.0488 s/iter. Eval: 0.0006 s/iter. Total: 0.0508 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 110/245. Dataloading: 0.0018 s/iter. Inference: 0.0488 s/iter. Eval: 0.0004 s/iter. Total: 0.0510 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 209/245. Dataloading: 0.0018 s/iter. Inference: 0.0485 s/iter. Eval: 0.0004 s/iter. Total: 0.0508 s/iter. ETA=0:00:01\n",
            "\u001b[32m[01/11 01:22:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.357196 (0.051488 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048556 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:22:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:22:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.51s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
            "\u001b[32m[01/11 01:22:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.102 | 0.350  | 0.000  | 0.000 | 0.000 | 0.158 |\n",
            "\u001b[32m[01/11 01:22:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.102 |\n",
            "\u001b[32m[01/11 01:22:04 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:22:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:22:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:22:04 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1023,0.3501,0.0000,0.0000,0.0000,0.1577\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:22:12 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:22:12 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:22:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:22:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:22:12 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:22:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:22:12 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:22:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0011 s/iter. Inference: 0.0477 s/iter. Eval: 0.0003 s/iter. Total: 0.0492 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 107/245. Dataloading: 0.0022 s/iter. Inference: 0.0492 s/iter. Eval: 0.0005 s/iter. Total: 0.0520 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 204/245. Dataloading: 0.0019 s/iter. Inference: 0.0496 s/iter. Eval: 0.0005 s/iter. Total: 0.0520 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.588880 (0.052454 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049450 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.24s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.158 | 0.572  | 0.000  | 0.000 | 0.007 | 0.317 |\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.158 |\n",
            "\u001b[32m[01/11 01:22:25 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:22:25 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1579,0.5723,0.0000,0.0000,0.0074,0.3168\n",
            "\u001b[32m[01/11 01:22:25 d2.utils.events]: \u001b[0m eta: 1:04:02  iter: 19  total_loss: 1.835  loss_cls: 0.8822  loss_box_reg: 0.5944  loss_rpn_cls: 0.3376  loss_rpn_loc: 0.02782    time: 0.7665  last_time: 0.7717  data_time: 0.0570  last_data_time: 0.0287   lr: 4.9953e-06  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:22:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:22:34 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:22:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:22:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:22:34 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:22:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:22:34 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:22:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0010 s/iter. Inference: 0.0504 s/iter. Eval: 0.0004 s/iter. Total: 0.0518 s/iter. ETA=0:00:12\n",
            "\u001b[32m[01/11 01:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 112/245. Dataloading: 0.0014 s/iter. Inference: 0.0480 s/iter. Eval: 0.0004 s/iter. Total: 0.0498 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 210/245. Dataloading: 0.0016 s/iter. Inference: 0.0484 s/iter. Eval: 0.0004 s/iter. Total: 0.0504 s/iter. ETA=0:00:01\n",
            "\u001b[32m[01/11 01:22:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.759656 (0.053165 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048464 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.111 | 0.640  | 0.002  | 0.000 | 0.015 | 0.198 |\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.111 |\n",
            "\u001b[32m[01/11 01:22:48 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:22:48 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1106,0.6405,0.0025,0.0000,0.0152,0.1981\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:22:56 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:22:56 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:22:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:22:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:22:56 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:22:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:22:56 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:22:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0010 s/iter. Inference: 0.0482 s/iter. Eval: 0.0004 s/iter. Total: 0.0496 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 111/245. Dataloading: 0.0014 s/iter. Inference: 0.0485 s/iter. Eval: 0.0004 s/iter. Total: 0.0504 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 209/245. Dataloading: 0.0017 s/iter. Inference: 0.0487 s/iter. Eval: 0.0004 s/iter. Total: 0.0509 s/iter. ETA=0:00:01\n",
            "\u001b[32m[01/11 01:23:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.351476 (0.051464 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048624 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:23:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:23:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.59s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
            "\u001b[32m[01/11 01:23:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.211 | 1.178  | 0.008  | 0.000 | 0.049 | 0.422 |\n",
            "\u001b[32m[01/11 01:23:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.211 |\n",
            "\u001b[32m[01/11 01:23:10 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:23:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:23:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:23:10 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2107,1.1782,0.0081,0.0000,0.0490,0.4224\n",
            "\u001b[32m[01/11 01:23:10 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 39  total_loss: 1.878  loss_cls: 0.7999  loss_box_reg: 0.6183  loss_rpn_cls: 0.4051  loss_rpn_loc: 0.0304    time: 0.7752  last_time: 0.7610  data_time: 0.0330  last_data_time: 0.0224   lr: 9.9902e-06  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:23:18 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:23:18 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:23:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:23:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:23:18 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:23:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:23:18 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:23:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0011 s/iter. Inference: 0.0484 s/iter. Eval: 0.0004 s/iter. Total: 0.0499 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 109/245. Dataloading: 0.0022 s/iter. Inference: 0.0486 s/iter. Eval: 0.0004 s/iter. Total: 0.0513 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 200/245. Dataloading: 0.0018 s/iter. Inference: 0.0486 s/iter. Eval: 0.0027 s/iter. Total: 0.0532 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:23:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.822409 (0.053427 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048683 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:23:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:23:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
            "\u001b[32m[01/11 01:23:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.315 | 1.797  | 0.013  | 0.000 | 0.101 | 0.718 |\n",
            "\u001b[32m[01/11 01:23:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.315 |\n",
            "\u001b[32m[01/11 01:23:33 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:23:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:23:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:23:33 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3151,1.7973,0.0130,0.0000,0.1011,0.7181\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:23:41 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:23:41 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:23:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:23:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:23:41 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:23:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:23:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:23:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:23:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0011 s/iter. Inference: 0.0482 s/iter. Eval: 0.0004 s/iter. Total: 0.0496 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 108/245. Dataloading: 0.0017 s/iter. Inference: 0.0492 s/iter. Eval: 0.0004 s/iter. Total: 0.0515 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 206/245. Dataloading: 0.0018 s/iter. Inference: 0.0492 s/iter. Eval: 0.0004 s/iter. Total: 0.0515 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:23:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.600539 (0.052502 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049579 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:23:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:23:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:23:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
            "\u001b[32m[01/11 01:23:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.475 | 2.253  | 0.022  | 0.000 | 0.132 | 1.180 |\n",
            "\u001b[32m[01/11 01:23:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.475 |\n",
            "\u001b[32m[01/11 01:23:56 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:23:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:23:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:23:56 d2.evaluation.testing]: \u001b[0mcopypaste: 0.4750,2.2532,0.0218,0.0000,0.1325,1.1795\n",
            "\u001b[32m[01/11 01:23:56 d2.utils.events]: \u001b[0m eta: 1:03:10  iter: 59  total_loss: 1.636  loss_cls: 0.6645  loss_box_reg: 0.6329  loss_rpn_cls: 0.1954  loss_rpn_loc: 0.01608    time: 0.7786  last_time: 0.7643  data_time: 0.0325  last_data_time: 0.0210   lr: 1.4985e-05  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:24:04 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:24:04 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:24:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:24:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:24:04 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:24:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:24:04 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:24:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0010 s/iter. Inference: 0.0485 s/iter. Eval: 0.0004 s/iter. Total: 0.0499 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 110/245. Dataloading: 0.0014 s/iter. Inference: 0.0489 s/iter. Eval: 0.0004 s/iter. Total: 0.0508 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 208/245. Dataloading: 0.0014 s/iter. Inference: 0.0491 s/iter. Eval: 0.0004 s/iter. Total: 0.0509 s/iter. ETA=0:00:01\n",
            "\u001b[32m[01/11 01:24:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.484160 (0.052017 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:24:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049439 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:24:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:24:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:24:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.25s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
            "\u001b[32m[01/11 01:24:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.604 | 2.855  | 0.031  | 0.000 | 0.166 | 1.606 |\n",
            "\u001b[32m[01/11 01:24:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.604 |\n",
            "\u001b[32m[01/11 01:24:20 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:24:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:24:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:24:20 d2.evaluation.testing]: \u001b[0mcopypaste: 0.6039,2.8550,0.0311,0.0000,0.1662,1.6058\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:24:27 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:24:27 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:24:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:24:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:24:27 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:24:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:24:27 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:24:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0032 s/iter. Inference: 0.0478 s/iter. Eval: 0.0004 s/iter. Total: 0.0514 s/iter. ETA=0:00:12\n",
            "\u001b[32m[01/11 01:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 106/245. Dataloading: 0.0026 s/iter. Inference: 0.0498 s/iter. Eval: 0.0004 s/iter. Total: 0.0529 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 199/245. Dataloading: 0.0022 s/iter. Inference: 0.0507 s/iter. Eval: 0.0004 s/iter. Total: 0.0534 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.809853 (0.053374 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.050253 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:24:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:24:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:24:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.079\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
            "\u001b[32m[01/11 01:24:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.775 | 3.478  | 0.043  | 0.000 | 0.186 | 2.113 |\n",
            "\u001b[32m[01/11 01:24:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.775 |\n",
            "\u001b[32m[01/11 01:24:43 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:24:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:24:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:24:43 d2.evaluation.testing]: \u001b[0mcopypaste: 0.7747,3.4776,0.0431,0.0000,0.1861,2.1128\n",
            "\u001b[32m[01/11 01:24:43 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 79  total_loss: 1.646  loss_cls: 0.6125  loss_box_reg: 0.7279  loss_rpn_cls: 0.2544  loss_rpn_loc: 0.03194    time: 0.7760  last_time: 0.7645  data_time: 0.0319  last_data_time: 0.0186   lr: 1.998e-05  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:24:51 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:24:51 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:24:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:24:51 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:24:51 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:24:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:24:51 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:24:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0009 s/iter. Inference: 0.0542 s/iter. Eval: 0.0004 s/iter. Total: 0.0555 s/iter. ETA=0:00:12\n",
            "\u001b[32m[01/11 01:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 108/245. Dataloading: 0.0019 s/iter. Inference: 0.0498 s/iter. Eval: 0.0004 s/iter. Total: 0.0521 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 203/245. Dataloading: 0.0017 s/iter. Inference: 0.0504 s/iter. Eval: 0.0004 s/iter. Total: 0.0525 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.710382 (0.052960 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.050190 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:25:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:25:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            "\u001b[32m[01/11 01:25:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.958 | 4.443  | 0.044  | 0.000 | 0.230 | 2.494 |\n",
            "\u001b[32m[01/11 01:25:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 0.958 |\n",
            "\u001b[32m[01/11 01:25:07 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:25:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:25:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:25:07 d2.evaluation.testing]: \u001b[0mcopypaste: 0.9578,4.4427,0.0445,0.0000,0.2301,2.4944\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:25:14 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:25:14 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:25:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:25:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:25:14 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:25:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:25:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:25:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0043 s/iter. Inference: 0.0493 s/iter. Eval: 0.0004 s/iter. Total: 0.0541 s/iter. ETA=0:00:12\n",
            "\u001b[32m[01/11 01:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 107/245. Dataloading: 0.0026 s/iter. Inference: 0.0495 s/iter. Eval: 0.0004 s/iter. Total: 0.0526 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 205/245. Dataloading: 0.0024 s/iter. Inference: 0.0490 s/iter. Eval: 0.0004 s/iter. Total: 0.0518 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:25:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.594288 (0.052476 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049091 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:25:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:25:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.052\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
            "\u001b[32m[01/11 01:25:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.204 | 5.226  | 0.091  | 0.000 | 0.277 | 3.002 |\n",
            "\u001b[32m[01/11 01:25:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 1.204 |\n",
            "\u001b[32m[01/11 01:25:30 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:25:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:25:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:25:30 d2.evaluation.testing]: \u001b[0mcopypaste: 1.2041,5.2265,0.0912,0.0000,0.2771,3.0018\n",
            "\u001b[32m[01/11 01:25:30 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 99  total_loss: 1.468  loss_cls: 0.5591  loss_box_reg: 0.7045  loss_rpn_cls: 0.1321  loss_rpn_loc: 0.01591    time: 0.7755  last_time: 0.7943  data_time: 0.0349  last_data_time: 0.0370   lr: 2.4975e-05  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:25:38 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:25:38 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:25:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:25:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:25:38 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:25:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:25:38 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:25:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0010 s/iter. Inference: 0.0495 s/iter. Eval: 0.0004 s/iter. Total: 0.0510 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 109/245. Dataloading: 0.0015 s/iter. Inference: 0.0493 s/iter. Eval: 0.0004 s/iter. Total: 0.0512 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 206/245. Dataloading: 0.0014 s/iter. Inference: 0.0495 s/iter. Eval: 0.0004 s/iter. Total: 0.0514 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:25:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.511168 (0.052130 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049521 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:25:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:25:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:25:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.123\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "\u001b[32m[01/11 01:25:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.506 | 6.591  | 0.131  | 0.000 | 0.361 | 3.459 |\n",
            "\u001b[32m[01/11 01:25:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 1.506 |\n",
            "\u001b[32m[01/11 01:25:53 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:25:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:25:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:25:53 d2.evaluation.testing]: \u001b[0mcopypaste: 1.5061,6.5912,0.1307,0.0000,0.3612,3.4593\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:26:01 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:26:01 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:26:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:26:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:26:01 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:26:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:26:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:26:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0009 s/iter. Inference: 0.0484 s/iter. Eval: 0.0004 s/iter. Total: 0.0497 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 105/245. Dataloading: 0.0018 s/iter. Inference: 0.0508 s/iter. Eval: 0.0004 s/iter. Total: 0.0531 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 203/245. Dataloading: 0.0018 s/iter. Inference: 0.0500 s/iter. Eval: 0.0004 s/iter. Total: 0.0523 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:26:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.174609 (0.054894 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:26:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049940 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:26:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:26:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:26:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
            "\u001b[32m[01/11 01:26:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 1.934 | 8.362  | 0.127  | 0.000 | 0.433 | 4.093 |\n",
            "\u001b[32m[01/11 01:26:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 1.934 |\n",
            "\u001b[32m[01/11 01:26:17 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:26:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:26:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:26:17 d2.evaluation.testing]: \u001b[0mcopypaste: 1.9337,8.3616,0.1270,0.0000,0.4327,4.0929\n",
            "\u001b[32m[01/11 01:26:17 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 119  total_loss: 1.475  loss_cls: 0.5246  loss_box_reg: 0.7461  loss_rpn_cls: 0.127  loss_rpn_loc: 0.02243    time: 0.7758  last_time: 0.7679  data_time: 0.0334  last_data_time: 0.0245   lr: 2.997e-05  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:26:25 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:26:25 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:26:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:26:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:26:25 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:26:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:26:25 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:26:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0037 s/iter. Inference: 0.0475 s/iter. Eval: 0.0004 s/iter. Total: 0.0516 s/iter. ETA=0:00:12\n",
            "\u001b[32m[01/11 01:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 110/245. Dataloading: 0.0016 s/iter. Inference: 0.0488 s/iter. Eval: 0.0004 s/iter. Total: 0.0509 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 209/245. Dataloading: 0.0016 s/iter. Inference: 0.0488 s/iter. Eval: 0.0004 s/iter. Total: 0.0509 s/iter. ETA=0:00:01\n",
            "\u001b[32m[01/11 01:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.369955 (0.051541 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048719 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:26:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:26:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:26:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
            "\u001b[32m[01/11 01:26:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.335 | 10.813 | 0.162  | 0.000 | 0.622 | 4.408 |\n",
            "\u001b[32m[01/11 01:26:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 2.335 |\n",
            "\u001b[32m[01/11 01:26:40 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:26:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:26:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:26:40 d2.evaluation.testing]: \u001b[0mcopypaste: 2.3348,10.8135,0.1622,0.0000,0.6216,4.4076\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:26:48 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:26:48 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:26:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:26:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:26:48 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:26:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:26:48 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:26:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0010 s/iter. Inference: 0.0486 s/iter. Eval: 0.0004 s/iter. Total: 0.0500 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 107/245. Dataloading: 0.0015 s/iter. Inference: 0.0500 s/iter. Eval: 0.0004 s/iter. Total: 0.0520 s/iter. ETA=0:00:07\n",
            "\u001b[32m[01/11 01:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 197/245. Dataloading: 0.0016 s/iter. Inference: 0.0493 s/iter. Eval: 0.0027 s/iter. Total: 0.0538 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:27:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.949056 (0.053954 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.049347 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:27:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:27:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            "\u001b[32m[01/11 01:27:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 2.817 | 12.386 | 0.213  | 0.000 | 0.767 | 5.093 |\n",
            "\u001b[32m[01/11 01:27:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 2.817 |\n",
            "\u001b[32m[01/11 01:27:03 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:27:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:27:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:27:03 d2.evaluation.testing]: \u001b[0mcopypaste: 2.8172,12.3857,0.2135,0.0000,0.7669,5.0930\n",
            "\u001b[32m[01/11 01:27:03 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 139  total_loss: 1.42  loss_cls: 0.4968  loss_box_reg: 0.7813  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.02672    time: 0.7759  last_time: 0.7790  data_time: 0.0321  last_data_time: 0.0275   lr: 3.4965e-05  max_mem: 9595M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:27:11 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:27:11 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:27:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:27:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:27:11 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:27:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:27:11 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:27:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0011 s/iter. Inference: 0.0481 s/iter. Eval: 0.0004 s/iter. Total: 0.0496 s/iter. ETA=0:00:11\n",
            "\u001b[32m[01/11 01:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 109/245. Dataloading: 0.0016 s/iter. Inference: 0.0492 s/iter. Eval: 0.0004 s/iter. Total: 0.0512 s/iter. ETA=0:00:06\n",
            "\u001b[32m[01/11 01:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 206/245. Dataloading: 0.0020 s/iter. Inference: 0.0490 s/iter. Eval: 0.0004 s/iter. Total: 0.0515 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:27:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.490532 (0.052044 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048956 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:27:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:27:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370\n",
            "\u001b[32m[01/11 01:27:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.228 | 14.367 | 0.220  | 0.000 | 0.975 | 5.425 |\n",
            "\u001b[32m[01/11 01:27:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 3.228 |\n",
            "\u001b[32m[01/11 01:27:26 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:27:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:27:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:27:26 d2.evaluation.testing]: \u001b[0mcopypaste: 3.2283,14.3666,0.2197,0.0000,0.9750,5.4252\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/11 01:27:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/11 01:27:34 d2.data.datasets.coco]: \u001b[0mLoaded 245 images in COCO format from /root/.cache/kagglehub/datasets/jaidalmotra/weed-detection/versions/1/test/_annotations.coco.json\n",
            "\u001b[32m[01/11 01:27:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[01/11 01:27:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[01/11 01:27:34 d2.data.common]: \u001b[0mSerializing 245 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[01/11 01:27:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
            "\u001b[32m[01/11 01:27:34 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
            "\u001b[32m[01/11 01:27:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 245 batches\n",
            "\u001b[32m[01/11 01:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/245. Dataloading: 0.0026 s/iter. Inference: 0.0529 s/iter. Eval: 0.0007 s/iter. Total: 0.0562 s/iter. ETA=0:00:13\n",
            "\u001b[32m[01/11 01:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 101/245. Dataloading: 0.0018 s/iter. Inference: 0.0489 s/iter. Eval: 0.0051 s/iter. Total: 0.0559 s/iter. ETA=0:00:08\n",
            "\u001b[32m[01/11 01:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 198/245. Dataloading: 0.0020 s/iter. Inference: 0.0491 s/iter. Eval: 0.0027 s/iter. Total: 0.0539 s/iter. ETA=0:00:02\n",
            "\u001b[32m[01/11 01:27:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.908887 (0.053787 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.048839 s / iter per device, on 1 devices)\n",
            "\u001b[32m[01/11 01:27:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/11 01:27:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/weed_val/coco_instances_results.json\n",
            "\u001b[32m[01/11 01:27:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.29s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
            "\u001b[32m[01/11 01:27:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 3.832 | 16.127 | 0.253  | 0.001 | 1.358 | 5.953 |\n",
            "\u001b[32m[01/11 01:27:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category    | AP   | category       | AP    |\n",
            "|:------------|:-----|:---------------|:------|\n",
            "| grass-weeds | nan  | 0 ridderzuring | 3.832 |\n",
            "\u001b[32m[01/11 01:27:50 d2.engine.defaults]: \u001b[0mEvaluation results for weed_val in csv format:\n",
            "\u001b[32m[01/11 01:27:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[01/11 01:27:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[01/11 01:27:50 d2.evaluation.testing]: \u001b[0mcopypaste: 3.8324,16.1269,0.2529,0.0006,1.3576,5.9529\n",
            "\u001b[32m[01/11 01:27:50 d2.utils.events]: \u001b[0m eta: 1:01:55  iter: 159  total_loss: 1.384  loss_cls: 0.4434  loss_box_reg: 0.7089  loss_rpn_cls: 0.1628  loss_rpn_loc: 0.03564    time: 0.7760  last_time: 0.7811  data_time: 0.0370  last_data_time: 0.0337   lr: 3.996e-05  max_mem: 9595M\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"weed_train\",)\n",
        "cfg.DATASETS.TEST = (\"weed_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "# Load pre-trained weights\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# Set number of classes (2 classes: grass-weeds and ridderzuring)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "\n",
        "# Training parameters\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = []  # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
        "\n",
        "# Evaluation parameters\n",
        "cfg.TEST.EVAL_PERIOD = 10  # Evaluate every 50 iterations\n",
        "cfg.VIS_PERIOD = 10  # Visualize predictions every 50 iterations\n",
        "\n",
        "# Initialize the output directory\n",
        "cfg.OUTPUT_DIR = \"./output\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"Training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./output\n"
          ]
        }
      ],
      "source": [
        "print (cfg.OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kblA1IyFvWbT"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API.\n",
        "This gives an AP of ~70. Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9tECBQCvMv3",
        "outputId": "c9f72ae9-d23c-44f7-8c52-8dd575400810"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'detectron2.evaluation'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COCOEvaluator, inference_on_dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_detection_test_loader\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m COCOEvaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweed_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2.evaluation'"
          ]
        }
      ],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"weed_val\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"weed_val\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
